{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2-time-series-forecasting-using-multi-layer-perceptron.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNicz0tVmHowfHIDULvWI/j",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahiakela/deep-learning-for-time-series-forecasting/blob/part-3-deep-learning-methods/2_time_series_forecasting_using_multi_layer_perceptron.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "szrTry_VwCCB",
        "colab_type": "text"
      },
      "source": [
        "# Time Series Forecasting using Multi-Layer Perceptron"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hnTR5fh3wYis",
        "colab_type": "text"
      },
      "source": [
        "Multilayer Perceptrons, or MLPs for short, can be applied to time series forecasting. A challenge with using MLPs for time series forecasting is in the preparation of the data. Specifically, lag observations must be  attened into feature vectors. \n",
        "\n",
        "In this notebook, we will discover how to develop a suite of Multilayer Perceptron models for a range of standard time series forecasting problems.\n",
        "\n",
        "* Develop MLP models for univariate time series forecasting.\n",
        "* Develop MLP models for multivariate time series forecasting.\n",
        "* Develop MLP models for multi-step time series forecasting.\n",
        "\n",
        "So the notebook is divided into four parts; they are:\n",
        "\n",
        "1. Univariate MLP Models\n",
        "2. Multivariate MLP Models\n",
        "3. Multi-step MLP Models\n",
        "4. Multivariate Multi-step MLP Models\n",
        "\n",
        "Traditionally, a lot of research has been invested into using MLPs for time series forecasting with modest results. Perhaps the most promising area in the application of deep learning methods to time series forecasting are in the use of CNNs, LSTMs and hybrid models. As such, we will not see more examples of straight MLP models for time series forecasting."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XMjdgNetxAN3",
        "colab_type": "text"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5aSxvjgkw8ZB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Dense, Input, concatenate\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kInTkXbVw8y9",
        "colab_type": "text"
      },
      "source": [
        "## Univariate MLP Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ORsCwVUQw98l",
        "colab_type": "text"
      },
      "source": [
        "Multilayer Perceptrons, or MLPs for short, can be used to model univariate time series forecasting problems. Univariate time series are a dataset comprised of a single series of observations with a temporal ordering and a model is required to learn from the series of past observations to predict the next value in the sequence. This section is divided into two parts; they are:\n",
        "\n",
        "1. Data Preparation\n",
        "2. MLP Model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sCzSMP5d5uu3",
        "colab_type": "text"
      },
      "source": [
        "### Data Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d8p85Rbr5v4O",
        "colab_type": "text"
      },
      "source": [
        "Before a univariate series can be modeled, it must be prepared. The MLP model will learn a function that maps a sequence of past observations as input to an output observation. As such, the sequence of observations must be transformed into multiple examples from which the model can learn.\n",
        "\n",
        "```python\n",
        "[10, 20, 30, 40, 50, 60, 70, 80, 90]\n",
        "```\n",
        "\n",
        "We can divide the sequence into multiple input/output patterns called samples, where three time steps are used as input and one time step is used as output for the one-step prediction that is being learned.\n",
        "\n",
        "```python\n",
        "X,          y\n",
        "10, 20, 30, 40\n",
        "20, 30, 40, 50\n",
        "30, 40, 50, 60\n",
        "..............\n",
        "```\n",
        "\n",
        "The split sequence() function below implements this behavior and will split a given univariate sequence into multiple samples where each sample has a specified number of time steps and the output is a single time step.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lVv34XH8y3pU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# split a univariate sequence into samples\n",
        "def split_sequence(sequence, n_steps):\n",
        "  X, y = list(), list()\n",
        "  for i in range(len(sequence)):\n",
        "    # find the end of this pattern\n",
        "    end_ix = i + n_steps\n",
        "    # check if we are beyond the sequence\n",
        "    if end_ix > len(sequence) - 1:\n",
        "      break\n",
        "    # gather input and output parts of the pattern\n",
        "    seq_x, seq_y = sequence[i:end_ix], sequence[end_ix]\n",
        "    X.append(seq_x)\n",
        "    y.append(seq_y)\n",
        "  return np.array(X), np.array(y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9TCdYLLv6u7W",
        "colab_type": "code",
        "outputId": "689f3049-ba0f-486d-bece-71a8ff37a568",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "# define input sequence\n",
        "raw_seq = [10, 20, 30, 40, 50, 60, 70, 80, 90]\n",
        "\n",
        "# choose a number of time steps\n",
        "n_steps = 3\n",
        "\n",
        "# split into samples\n",
        "X, y = split_sequence(raw_seq, n_steps)\n",
        "\n",
        "# summarize the data\n",
        "for i in range(len(X)):\n",
        "  print(X[i], y[i])"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[10 20 30] 40\n",
            "[20 30 40] 50\n",
            "[30 40 50] 60\n",
            "[40 50 60] 70\n",
            "[50 60 70] 80\n",
            "[60 70 80] 90\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tYNzqAZx6Tsa",
        "colab_type": "text"
      },
      "source": [
        "Now that we know how to prepare a univariate series for modeling, let's look at developing an MLP model that can learn the mapping of inputs to outputs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NUMZ_lEJ6fAD",
        "colab_type": "text"
      },
      "source": [
        "### MLP Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "djbd23Ck6hdj",
        "colab_type": "text"
      },
      "source": [
        "A simple MLP model has a single hidden layer of nodes, and an output layer used to make a prediction.\n",
        "\n",
        "We almost always have multiple samples, therefore, the model will expect the input component of training data to have the dimensions or shape: $[samples, features]$.\n",
        "\n",
        "The model expects the input shape to be two-dimensional with $[samples,\n",
        "features]$, therefore, we must reshape the single input sample before making the prediction, e.g with the shape [1, 3] for 1 sample and 3 time steps used as input features.\n",
        "\n",
        "We can make this concept concrete with a worked example.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WfGFjg9k2wvf",
        "colab_type": "code",
        "outputId": "9ee8f6f4-0653-479b-ee6e-a25198f02f78",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(100, activation='relu', input_dim=n_steps))\n",
        "model.add(Dense(1))\n",
        "\n",
        "# compile model'\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "# fit model\n",
        "model.fit(X, y, epochs=200, verbose=0)\n",
        "\n",
        "# demonstrate prediction\n",
        "x_input = np.array([70, 80, 90])\n",
        "x_input = x_input.reshape((1, n_steps))\n",
        "yhat = model.predict(x_input, verbose=0)\n",
        "print(yhat)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[109.83776]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-BBZ_TAlUSWR",
        "colab_type": "text"
      },
      "source": [
        "## Multivariate MLP Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rnYwRaK4UYIV",
        "colab_type": "text"
      },
      "source": [
        "Consider that you are in the current situation:\n",
        "\n",
        "``\n",
        "I have two columns in my data file with 5,000 rows, column 1 is time (with 1 hour interval) and column 2 is the number of sales and I am trying to forecast the number of sales for future time steps. Help me to set the number of samples, time steps and features in this data for an LSTM?\n",
        "``\n",
        "\n",
        "There are few problems here:\n",
        "\n",
        "* **Data Shape**: LSTMs expect 3D input, and it can be challenging to get your head around this the first time.\n",
        "* **Sequence Length**: LSTMs don't like sequences of more than 200-400 time steps, so the data will need to be split into subsamples.\n",
        "\n",
        "We will work through this example, broken down into the following 4 steps:\n",
        "\n",
        "1. Load the Data\n",
        "2. Drop the Time Column\n",
        "3. Split Into Samples\n",
        "4. Reshape Subsequences\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-gyJQj3q9pi_",
        "colab_type": "text"
      },
      "source": [
        "### Load the Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZmkMCCYbTyXt",
        "colab_type": "code",
        "outputId": "ea735bb6-63ab-4c06-afa4-86caf0c41920",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "# load time series dataset\n",
        "# series = pd.read_csv('filename.csv', header=0, index_col=0)\n",
        "\n",
        "# We will mock loading by defining a new dataset in memory with 5,000 time steps.\n",
        "# define the dataset\n",
        "data = list()\n",
        "n = 5000\n",
        "for i in range(n):\n",
        "  data.append([i+1, (i+1) * 10])\n",
        "data = np.array(data)\n",
        "print(data[:5, :])\n",
        "print(data.shape)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 1 10]\n",
            " [ 2 20]\n",
            " [ 3 30]\n",
            " [ 4 40]\n",
            " [ 5 50]]\n",
            "(5000, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zw-RUV2f_Yd2",
        "colab_type": "text"
      },
      "source": [
        "We can see we have 5,000 rows and 2 columns: a standard univariate time series dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "542e2v6C_dG2",
        "colab_type": "text"
      },
      "source": [
        "### Drop the Time Column"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WAjSbvB1_eJF",
        "colab_type": "text"
      },
      "source": [
        "If your time series data is uniform over time and there is no missing values, we can drop the time column. If not, you may want to look at imputing the missing values, resampling the data to a new time scale, or developing a model that can handle missing values. \n",
        "\n",
        "Here, we just drop the first column:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8mjJx7WA-616",
        "colab_type": "code",
        "outputId": "48d1f8cb-92e4-40cd-fc6b-3a37de963b54",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# define the dataset\n",
        "data = list()\n",
        "n = 5000\n",
        "for i in range(n):\n",
        "  data.append([i+1, (i+1) * 10])\n",
        "data = np.array(data)\n",
        "\n",
        "# drop time\n",
        "data = data[:, 1]\n",
        "print(data.shape)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "87O-C78ZAmCe",
        "colab_type": "text"
      },
      "source": [
        "### Split Into Samples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zgUU1CGtAmz7",
        "colab_type": "text"
      },
      "source": [
        "LSTMs need to process samples where each sample is a single sequence of observations. In this case, 5,000 time steps is too long; LSTMs work better with 200-to-400 time steps. Therefore, we need to split the 5,000 time steps into multiple shorter sub-sequences.\n",
        "\n",
        "For example, perhaps you need overlapping sequences, perhaps non-overlapping is good but your model needs state across the sub-sequences and so on. \n",
        "\n",
        "In this example, we will split the 5,000 time steps into 25 sub-sequences of 200 time steps each."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8I7z_g2GAOOL",
        "colab_type": "code",
        "outputId": "e2d4f522-4502-462e-f726-6e8803555313",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# define the dataset\n",
        "data = list()\n",
        "n = 5000\n",
        "for i in range(n):\n",
        "  data.append([i+1, (i+1) * 10])\n",
        "data = np.array(data)\n",
        "\n",
        "# drop time\n",
        "data = data[:, 1]\n",
        "print(data.shape)\n",
        "\n",
        "# split into samples (e.g. 5000/200 = 25)\n",
        "samples = list()\n",
        "length = 200\n",
        "\n",
        "# step over the 5,000 in jumps of 200\n",
        "for i in range(0, n , length):\n",
        "  sample = data[i: i + length]  # grab from i to i + 200\n",
        "  samples.append(sample)\n",
        "print(len(samples))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5000,)\n",
            "25\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_a-AsEPVBtoz",
        "colab_type": "code",
        "outputId": "f3249824-258a-4eeb-e7f9-b32af9a3cd69",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(samples[:5][0])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "200"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mLGjwEFHB46O",
        "colab_type": "code",
        "outputId": "7314a30f-2c79-49dc-951c-917467f6cc49",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 663
        }
      },
      "source": [
        "samples[:2]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([  10,   20,   30,   40,   50,   60,   70,   80,   90,  100,  110,\n",
              "         120,  130,  140,  150,  160,  170,  180,  190,  200,  210,  220,\n",
              "         230,  240,  250,  260,  270,  280,  290,  300,  310,  320,  330,\n",
              "         340,  350,  360,  370,  380,  390,  400,  410,  420,  430,  440,\n",
              "         450,  460,  470,  480,  490,  500,  510,  520,  530,  540,  550,\n",
              "         560,  570,  580,  590,  600,  610,  620,  630,  640,  650,  660,\n",
              "         670,  680,  690,  700,  710,  720,  730,  740,  750,  760,  770,\n",
              "         780,  790,  800,  810,  820,  830,  840,  850,  860,  870,  880,\n",
              "         890,  900,  910,  920,  930,  940,  950,  960,  970,  980,  990,\n",
              "        1000, 1010, 1020, 1030, 1040, 1050, 1060, 1070, 1080, 1090, 1100,\n",
              "        1110, 1120, 1130, 1140, 1150, 1160, 1170, 1180, 1190, 1200, 1210,\n",
              "        1220, 1230, 1240, 1250, 1260, 1270, 1280, 1290, 1300, 1310, 1320,\n",
              "        1330, 1340, 1350, 1360, 1370, 1380, 1390, 1400, 1410, 1420, 1430,\n",
              "        1440, 1450, 1460, 1470, 1480, 1490, 1500, 1510, 1520, 1530, 1540,\n",
              "        1550, 1560, 1570, 1580, 1590, 1600, 1610, 1620, 1630, 1640, 1650,\n",
              "        1660, 1670, 1680, 1690, 1700, 1710, 1720, 1730, 1740, 1750, 1760,\n",
              "        1770, 1780, 1790, 1800, 1810, 1820, 1830, 1840, 1850, 1860, 1870,\n",
              "        1880, 1890, 1900, 1910, 1920, 1930, 1940, 1950, 1960, 1970, 1980,\n",
              "        1990, 2000]),\n",
              " array([2010, 2020, 2030, 2040, 2050, 2060, 2070, 2080, 2090, 2100, 2110,\n",
              "        2120, 2130, 2140, 2150, 2160, 2170, 2180, 2190, 2200, 2210, 2220,\n",
              "        2230, 2240, 2250, 2260, 2270, 2280, 2290, 2300, 2310, 2320, 2330,\n",
              "        2340, 2350, 2360, 2370, 2380, 2390, 2400, 2410, 2420, 2430, 2440,\n",
              "        2450, 2460, 2470, 2480, 2490, 2500, 2510, 2520, 2530, 2540, 2550,\n",
              "        2560, 2570, 2580, 2590, 2600, 2610, 2620, 2630, 2640, 2650, 2660,\n",
              "        2670, 2680, 2690, 2700, 2710, 2720, 2730, 2740, 2750, 2760, 2770,\n",
              "        2780, 2790, 2800, 2810, 2820, 2830, 2840, 2850, 2860, 2870, 2880,\n",
              "        2890, 2900, 2910, 2920, 2930, 2940, 2950, 2960, 2970, 2980, 2990,\n",
              "        3000, 3010, 3020, 3030, 3040, 3050, 3060, 3070, 3080, 3090, 3100,\n",
              "        3110, 3120, 3130, 3140, 3150, 3160, 3170, 3180, 3190, 3200, 3210,\n",
              "        3220, 3230, 3240, 3250, 3260, 3270, 3280, 3290, 3300, 3310, 3320,\n",
              "        3330, 3340, 3350, 3360, 3370, 3380, 3390, 3400, 3410, 3420, 3430,\n",
              "        3440, 3450, 3460, 3470, 3480, 3490, 3500, 3510, 3520, 3530, 3540,\n",
              "        3550, 3560, 3570, 3580, 3590, 3600, 3610, 3620, 3630, 3640, 3650,\n",
              "        3660, 3670, 3680, 3690, 3700, 3710, 3720, 3730, 3740, 3750, 3760,\n",
              "        3770, 3780, 3790, 3800, 3810, 3820, 3830, 3840, 3850, 3860, 3870,\n",
              "        3880, 3890, 3900, 3910, 3920, 3930, 3940, 3950, 3960, 3970, 3980,\n",
              "        3990, 4000])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IbVK-Ys3CYwX",
        "colab_type": "text"
      },
      "source": [
        "We now have 25 subsequences of 200 time steps each."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xz_5OcmkCZgA",
        "colab_type": "text"
      },
      "source": [
        "### Reshape Subsequences"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0uUaycRYCb2p",
        "colab_type": "text"
      },
      "source": [
        "The LSTM needs data with the format of $[samples, timesteps, features]$. We have 25 samples, 200 time steps per sample, and 1 feature. \n",
        "\n",
        "First, we need to convert our list of arrays into a 2D NumPy array with the shape $[25, 200]$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q3ajkmluCJRv",
        "colab_type": "code",
        "outputId": "2771c2f4-35d9-4fa1-dc0c-a6ff0e7513d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# define the dataset\n",
        "data = list()\n",
        "n = 5000\n",
        "for i in range(n):\n",
        "  data.append([i+1, (i+1) * 10])\n",
        "data = np.array(data)\n",
        "\n",
        "# drop time\n",
        "data = data[:, 1]\n",
        "print(data.shape)\n",
        "\n",
        "# split into samples (e.g. 5000/200 = 25)\n",
        "samples = list()\n",
        "length = 200\n",
        "\n",
        "# step over the 5,000 in jumps of 200\n",
        "for i in range(0, n , length):\n",
        "  sample = data[i: i + length]  # grab from i to i + 200\n",
        "  samples.append(sample)\n",
        "print(len(samples))\n",
        "\n",
        "# convert list of arrays into 2d array\n",
        "data = np.array(samples)\n",
        "print(data.shape)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5000,)\n",
            "25\n",
            "(25, 200)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D8h6xdRHDhSw",
        "colab_type": "text"
      },
      "source": [
        "Now we have 25 rows and 200 columns. Interpreted in a machine learning context, this dataset has 25 samples and 200 features per sample.\n",
        "\n",
        "Next, we can use the reshape() function to add one additional dimension for our single feature and use the existing columns as time steps instead."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XtVdYk5GDVxS",
        "colab_type": "code",
        "outputId": "8acba634-df71-43ca-c414-28f5f0e5a2b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# reshape into [samples, timesteps, features]\n",
        "data = data.reshape((len(samples), length, 1))\n",
        "print(data.shape)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(25, 200, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PLR6f3RUEMTj",
        "colab_type": "text"
      },
      "source": [
        "And that is it. The data can now be used as an input (X) to an LSTM model, or even a CNN model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bx7ieEyCIj8s",
        "colab_type": "text"
      },
      "source": [
        "## Multivariate MLP Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p8oXosMQIkw2",
        "colab_type": "text"
      },
      "source": [
        "Multivariate time series data means data where there is more than one observation for each time step. There are two main models that we may require with multivariate time series data.\n",
        "\n",
        "1. Multiple Input Series.\n",
        "2. Multiple Parallel Series.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tLGBn-9yLtxV",
        "colab_type": "text"
      },
      "source": [
        "### Multiple Input Series"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4rarrBIxLt7t",
        "colab_type": "text"
      },
      "source": [
        "A problem may have two or more parallel input time series and an output time series that is dependent on the input time series. The input time series are parallel because each series has an observation at the same time step. \n",
        "\n",
        "We can demonstrate this with a simple example of two parallel input time series where the output series is the simple addition of the input series.\n",
        "\n",
        "We can reshape these three arrays of data as a single dataset where each row is a time step and each column is a separate time series. This is a standard way of storing parallel time series in a CSV file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CKWotZ0-L1gn",
        "colab_type": "code",
        "outputId": "9cb13aa6-fe30-4eca-c15a-884ef0b5e75e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "# define input sequence\n",
        "in_seq1 = np.array([10, 20, 30, 40, 50, 60, 70, 80, 90])\n",
        "in_seq2 = np.array([15, 25, 35, 45, 55, 65, 75, 85, 95])\n",
        "out_seq = np.array([in_seq1[i] + in_seq2[i] for i in range(len(in_seq1))])\n",
        "print(out_seq)\n",
        "\n",
        "# convert to [rows, columns] structure\n",
        "in_seq1 = in_seq1.reshape((len(in_seq1), 1))\n",
        "in_seq2 = in_seq2.reshape((len(in_seq2), 1))\n",
        "out_seq = out_seq.reshape((len(out_seq), 1))\n",
        "\n",
        "# horizontally stack columns\n",
        "dataset = np.hstack((in_seq1, in_seq2, out_seq))\n",
        "print(dataset)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 25  45  65  85 105 125 145 165 185]\n",
            "[[ 10  15  25]\n",
            " [ 20  25  45]\n",
            " [ 30  35  65]\n",
            " [ 40  45  85]\n",
            " [ 50  55 105]\n",
            " [ 60  65 125]\n",
            " [ 70  75 145]\n",
            " [ 80  85 165]\n",
            " [ 90  95 185]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eiJHq8PQTXAa",
        "colab_type": "text"
      },
      "source": [
        "As with the univariate time series, we must structure these data into samples with input and output samples. We need to split the data into samples maintaining the order of observations across the two input sequences. \n",
        "\n",
        "If we chose three input time steps, then the first sample would\n",
        "look as follows:\n",
        "\n",
        "```python\n",
        "Input:\n",
        "10, 15\n",
        "20, 25\n",
        "30, 35\n",
        "\n",
        "Output:\n",
        "65\n",
        "```\n",
        "\n",
        "That is, the first three time steps of each parallel series are provided as input to the model and the model associates this with the value in the output series at the third time step, in this case 65.\n",
        "\n",
        "We can see that, in transforming the time series into input/output samples to train the model, that we will have to discard some values from the output time series where we do not have values in the input time series at prior time steps. In turn, the choice of the size of the number of input time steps will have an important effect on how much of the training data is used.\n",
        "\n",
        "We can define a function named split sequences() that will take a dataset as we\n",
        "have defined it with rows for time steps and columns for parallel series and return input/output samples."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "psZy__7rOJuo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# split a multivariate sequence into samples\n",
        "def split_sequences(sequences, n_steps):\n",
        "  X, y = list(), list()\n",
        "  for i in range(len(sequences)):\n",
        "    # find the end of this pattern\n",
        "    end_ix = i + n_steps\n",
        "    # check if we are beyond the dataset\n",
        "    if end_ix > len(sequences):\n",
        "      break\n",
        "    # gather input and output parts of the pattern\n",
        "    seq_x, seq_y = sequences[i: end_ix, :-1], sequences[end_ix - 1, -1]\n",
        "    X.append(seq_x)\n",
        "    y.append(seq_y)\n",
        "  return np.array(X), np.array(y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Ai96SAFWMGQ",
        "colab_type": "text"
      },
      "source": [
        "We can test this function on our dataset using three time steps for each input time series as input."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4mbCzoykWF-H",
        "colab_type": "code",
        "outputId": "0fe66796-a17f-41d5-d17f-f0eee9a91c2a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        }
      },
      "source": [
        "# define input sequence\n",
        "in_seq1 = np.array([10, 20, 30, 40, 50, 60, 70, 80, 90])\n",
        "in_seq2 = np.array([15, 25, 35, 45, 55, 65, 75, 85, 95])\n",
        "out_seq = np.array([in_seq1[i] + in_seq2[i] for i in range(len(in_seq1))])\n",
        "print(out_seq)\n",
        "\n",
        "# convert to [rows, columns] structure\n",
        "in_seq1 = in_seq1.reshape((len(in_seq1), 1))\n",
        "in_seq2 = in_seq2.reshape((len(in_seq2), 1))\n",
        "out_seq = out_seq.reshape((len(out_seq), 1))\n",
        "\n",
        "# horizontally stack columns\n",
        "dataset = np.hstack((in_seq1, in_seq2, out_seq))\n",
        "print(dataset)\n",
        "\n",
        "# choose a number of time steps\n",
        "n_steps = 3\n",
        "\n",
        "# convert into input/output\n",
        "X, y = split_sequences(dataset, n_steps)\n",
        "print(X.shape, y.shape)\n",
        "\n",
        "# summarize the data\n",
        "for i in range(len(X)):\n",
        "  print(X[i], y[i])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 25  45  65  85 105 125 145 165 185]\n",
            "[[ 10  15  25]\n",
            " [ 20  25  45]\n",
            " [ 30  35  65]\n",
            " [ 40  45  85]\n",
            " [ 50  55 105]\n",
            " [ 60  65 125]\n",
            " [ 70  75 145]\n",
            " [ 80  85 165]\n",
            " [ 90  95 185]]\n",
            "(7, 3, 2) (7,)\n",
            "[[10 15]\n",
            " [20 25]\n",
            " [30 35]] 65\n",
            "[[20 25]\n",
            " [30 35]\n",
            " [40 45]] 85\n",
            "[[30 35]\n",
            " [40 45]\n",
            " [50 55]] 105\n",
            "[[40 45]\n",
            " [50 55]\n",
            " [60 65]] 125\n",
            "[[50 55]\n",
            " [60 65]\n",
            " [70 75]] 145\n",
            "[[60 65]\n",
            " [70 75]\n",
            " [80 85]] 165\n",
            "[[70 75]\n",
            " [80 85]\n",
            " [90 95]] 185\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aC7NOsO8XVEP",
        "colab_type": "text"
      },
      "source": [
        "We can see that the X component has a three-dimensional structure. The \frst dimension is the number of samples, in this case 7. The second dimension is the number of time steps per sample, in this case 3, the value speci\fed to the function. \n",
        "\n",
        "Finally, the last dimension specifies the number of parallel time series or the number of variables, in this case 2 for the two parallel series. We can then see that the input and output for each sample is printed, showing the three time steps for each of the two input series and the associated output for each sample."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zChTFTfBXk-_",
        "colab_type": "text"
      },
      "source": [
        "#### MLP Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r9-QT3GFXmQO",
        "colab_type": "text"
      },
      "source": [
        "Before we can fit an MLP on this data, we must flatten the shape of the input samples. MLPs require that the shape of the input portion of each sample is a vector. With a multivariate input, we will have multiple vectors, one for each time step. \n",
        "\n",
        "We can flatten the temporal structure of each input sample, so that:\n",
        "```python\n",
        "[[10 15]\n",
        "[20 25]\n",
        "[30 35]]\n",
        "\n",
        "Becomes:\n",
        "[10, 15, 20, 25, 30, 35]\n",
        "```\n",
        "\n",
        "**Step-1**:\n",
        "First, we can calculate the length of each input vector as the number of time steps multiplied by the number of features or time series. We can then use this vector size to reshape the input.\n",
        "\n",
        "**Step-2**:We can now define an MLP model for the multivariate input where the vector length is used for the input dimension argument.\n",
        "\n",
        "**Step-3**:When making a prediction, the model expects three time steps for two input time series.The shape of the 1 sample with 3 time steps and 2 variables would be $[1, 3, 2]$. We must again reshape this to be 1 sample with a vector of 6 elements or $[1, 6]$. We would expect the next value in the sequence to be 100 + 105 or 205.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CF4LMwB0WwC2",
        "colab_type": "code",
        "outputId": "9d9f5654-0a22-4e9f-9323-bf6f571ac4c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Step-1: flatten input\n",
        "n_input = X.shape[1] * X.shape[2]\n",
        "X = X.reshape((X.shape[0], n_input))\n",
        "\n",
        "# Step-2: define model\n",
        "model = Sequential()\n",
        "model.add(Dense(100, activation='relu', input_dim=n_input))\n",
        "model.add(Dense(1))\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "# fit the model\n",
        "model.fit(X, y, epochs=200, verbose=0)\n",
        "\n",
        "# Step-3: demonstrate prediction\n",
        "x_input = np.array([[80, 85], [90, 95], [100, 105]])\n",
        "x_input = x_input.reshape((1, n_input))\n",
        "yhat = model.predict(x_input, verbose=0)\n",
        "print(yhat)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[212.04596]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wwbA7rdaiQhv",
        "colab_type": "text"
      },
      "source": [
        "#### Multi-headed MLP Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rg6C4JqdiRuy",
        "colab_type": "text"
      },
      "source": [
        "There is another more elaborate way to model the problem. Each input series can be handled by a separate MLP and the output of each of these submodels can be combined before a prediction is made for the output sequence. We can refer to this as a multi-headed input MLP model. It may offer more  exibility or better performance depending on the specifics of the problem that are being modeled. This type of model can be defined in Keras using the Keras functional API.\n",
        "\n",
        "We can do this using the followings steps:\n",
        "\n",
        "* First, we can define the two input model as an MLP with an input layer that expects vectors with n steps features.\n",
        "* Now, we can merge the output from each model into one long vector, which can be interpreted before making a prediction for the output sequence.\n",
        "* We can then tie the inputs and outputs together.\n",
        "\n",
        "The image below provides a schematic for how this model looks, including the shape of the inputs and outputs of each layer.\n",
        "\n",
        "<img src='https://github.com/rahiakela/img-repo/blob/master/multi-headed-mlp.png?raw=1' width='800'/>\n",
        "\n",
        "This model requires input to be provided as a list of two elements, where each element in the list contains data for one of the submodels. In order to achieve this, we can split the 3D input data into two separate arrays of input data: that is from one array with the shape $[7, 3,2]$ to two 2D arrays with the shape $[7, 3]$.\n",
        "\n",
        "These data can then be provided in order to fit the model.\n",
        "\n",
        "Similarly, we must prepare the data for a single sample as two separate two-dimensional arrays when making a single one-step prediction.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CTXDx9EJhQtP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "143289f8-3b8b-4020-874e-aaf90659e62e"
      },
      "source": [
        "# define input sequence\n",
        "in_seq1 = np.array([10, 20, 30, 40, 50, 60, 70, 80, 90])\n",
        "in_seq2 = np.array([15, 25, 35, 45, 55, 65, 75, 85, 95])\n",
        "out_seq = np.array([in_seq1[i]+in_seq2[i] for i in range(len(in_seq1))])\n",
        "\n",
        "# convert to [rows, columns] structure\n",
        "in_seq1 = in_seq1.reshape((len(in_seq1), 1))\n",
        "in_seq2 = in_seq2.reshape((len(in_seq2), 1))\n",
        "out_seq = out_seq.reshape((len(out_seq), 1))\n",
        "\n",
        "# horizontally stack columns\n",
        "dataset = np.hstack((in_seq1, in_seq2, out_seq))\n",
        "\n",
        "# choose a number of time steps\n",
        "n_steps = 3\n",
        "\n",
        "# convert into input/output\n",
        "X, y = split_sequences(dataset, n_steps)\n",
        "\n",
        "# separate input data\n",
        "X1 = X[:, :, 0]\n",
        "X2 = X[:, :, 1]\n",
        "\n",
        "# first input model\n",
        "visible1 = Input(shape=(n_steps,))\n",
        "dense1 = Dense(100, activation='relu')(visible1)\n",
        "\n",
        "# second input model\n",
        "visible2 = Input(shape=(n_steps,))\n",
        "dense2 = Dense(100, activation='relu')(visible2)\n",
        "\n",
        "# merge input models\n",
        "merge = concatenate([dense1, dense2])\n",
        "output = Dense(1)(merge)\n",
        "model = Model(inputs=[visible1, visible2], outputs=output)\n",
        "\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "model.fit([X1, X2], y, epochs=2000, verbose=0)\n",
        "\n",
        "# demonstrate prediction\n",
        "x_input = np.array([[80, 85], [90, 95], [100, 105]])\n",
        "x1 = x_input[:, 0].reshape((1, n_steps))\n",
        "x2 = x_input[:, 1].reshape((1, n_steps))\n",
        "\n",
        "yhat = model.predict([x1, x2], verbose=0)\n",
        "print(yhat)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[206.63481]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IUh-HTVwRMiO",
        "colab_type": "text"
      },
      "source": [
        "### Multiple Parallel Series"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J9UjhuAdRhdj",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "15L9dqwQRLE8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}