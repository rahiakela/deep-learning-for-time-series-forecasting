{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2-time-series-forecasting-using-multi-layer-perceptron.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOBeTVHHq+yqeUoMjY6JrY4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahiakela/deep-learning-for-time-series-forecasting/blob/part-3-deep-learning-methods/2_time_series_forecasting_using_multi_layer_perceptron.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "szrTry_VwCCB",
        "colab_type": "text"
      },
      "source": [
        "# Time Series Forecasting using Multi-Layer Perceptron"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hnTR5fh3wYis",
        "colab_type": "text"
      },
      "source": [
        "Multilayer Perceptrons, or MLPs for short, can be applied to time series forecasting. A challenge with using MLPs for time series forecasting is in the preparation of the data. Specifically, lag observations must be  attened into feature vectors. \n",
        "\n",
        "In this notebook, we will discover how to develop a suite of Multilayer Perceptron models for a range of standard time series forecasting problems.\n",
        "\n",
        "* Develop MLP models for univariate time series forecasting.\n",
        "* Develop MLP models for multivariate time series forecasting.\n",
        "* Develop MLP models for multi-step time series forecasting.\n",
        "\n",
        "So the notebook is divided into four parts; they are:\n",
        "\n",
        "1. Univariate MLP Models\n",
        "2. Multivariate MLP Models\n",
        "3. Multi-step MLP Models\n",
        "4. Multivariate Multi-step MLP Models\n",
        "\n",
        "Traditionally, a lot of research has been invested into using MLPs for time series forecasting with modest results. Perhaps the most promising area in the application of deep learning methods to time series forecasting are in the use of CNNs, LSTMs and hybrid models. As such, we will not see more examples of straight MLP models for time series forecasting."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XMjdgNetxAN3",
        "colab_type": "text"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5aSxvjgkw8ZB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kInTkXbVw8y9",
        "colab_type": "text"
      },
      "source": [
        "## Univariate MLP Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ORsCwVUQw98l",
        "colab_type": "text"
      },
      "source": [
        "Multilayer Perceptrons, or MLPs for short, can be used to model univariate time series forecasting problems. Univariate time series are a dataset comprised of a single series of observations with a temporal ordering and a model is required to learn from the series of past observations to predict the next value in the sequence. This section is divided into two parts; they are:\n",
        "\n",
        "1. Data Preparation\n",
        "2. MLP Model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sCzSMP5d5uu3",
        "colab_type": "text"
      },
      "source": [
        "### Data Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d8p85Rbr5v4O",
        "colab_type": "text"
      },
      "source": [
        "Before a univariate series can be modeled, it must be prepared. The MLP model will learn a function that maps a sequence of past observations as input to an output observation. As such, the sequence of observations must be transformed into multiple examples from which the model can learn.\n",
        "\n",
        "```python\n",
        "[10, 20, 30, 40, 50, 60, 70, 80, 90]\n",
        "```\n",
        "\n",
        "We can divide the sequence into multiple input/output patterns called samples, where three time steps are used as input and one time step is used as output for the one-step prediction that is being learned.\n",
        "\n",
        "```python\n",
        "X,          y\n",
        "10, 20, 30, 40\n",
        "20, 30, 40, 50\n",
        "30, 40, 50, 60\n",
        "..............\n",
        "```\n",
        "\n",
        "The split sequence() function below implements this behavior and will split a given univariate sequence into multiple samples where each sample has a specified number of time steps and the output is a single time step.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lVv34XH8y3pU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# split a univariate sequence into samples\n",
        "def split_sequence(sequence, n_steps):\n",
        "  X, y = list(), list()\n",
        "  for i in range(len(sequence)):\n",
        "    # find the end of this pattern\n",
        "    end_ix = i + n_steps\n",
        "    # check if we are beyond the sequence\n",
        "    if end_ix > len(sequence) - 1:\n",
        "      break\n",
        "    # gather input and output parts of the pattern\n",
        "    seq_x, seq_y = sequence[i:end_ix], sequence[end_ix]\n",
        "    X.append(seq_x)\n",
        "    y.append(seq_y)\n",
        "  return np.array(X), np.array(y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9TCdYLLv6u7W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "bc30f8cd-347c-47f1-cb63-ba4443ba987d"
      },
      "source": [
        "# define input sequence\n",
        "raw_seq = [10, 20, 30, 40, 50, 60, 70, 80, 90]\n",
        "\n",
        "# choose a number of time steps\n",
        "n_steps = 3\n",
        "\n",
        "# split into samples\n",
        "X, y = split_sequence(raw_seq, n_steps)\n",
        "\n",
        "# summarize the data\n",
        "for i in range(len(X)):\n",
        "  print(X[i], y[i])"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[10 20 30] 40\n",
            "[20 30 40] 50\n",
            "[30 40 50] 60\n",
            "[40 50 60] 70\n",
            "[50 60 70] 80\n",
            "[60 70 80] 90\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tYNzqAZx6Tsa",
        "colab_type": "text"
      },
      "source": [
        "Now that we know how to prepare a univariate series for modeling, let's look at developing an MLP model that can learn the mapping of inputs to outputs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NUMZ_lEJ6fAD",
        "colab_type": "text"
      },
      "source": [
        "### MLP Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "djbd23Ck6hdj",
        "colab_type": "text"
      },
      "source": [
        "A simple MLP model has a single hidden layer of nodes, and an output layer used to make a prediction.\n",
        "\n",
        "We almost always have multiple samples, therefore, the model will expect the input component of training data to have the dimensions or shape: $[samples, features]$.\n",
        "\n",
        "The model expects the input shape to be two-dimensional with $[samples,\n",
        "features]$, therefore, we must reshape the single input sample before making the prediction, e.g with the shape [1, 3] for 1 sample and 3 time steps used as input features.\n",
        "\n",
        "We can make this concept concrete with a worked example.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WfGFjg9k2wvf",
        "colab_type": "code",
        "outputId": "c2931ebd-a59b-4706-ea5d-73ef1b8e8ce3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(100, activation='relu', input_dim=n_steps))\n",
        "model.add(Dense(1))\n",
        "\n",
        "# compile model'\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "# fit model\n",
        "model.fit(X, y, epochs=200, verbose=0)\n",
        "\n",
        "# demonstrate prediction\n",
        "x_input = np.array([70, 80, 90])\n",
        "x_input = x_input.reshape((1, n_steps))\n",
        "yhat = model.predict(x_input, verbose=0)\n",
        "print(yhat)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[108.95295]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-BBZ_TAlUSWR",
        "colab_type": "text"
      },
      "source": [
        "## Multivariate MLP Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rnYwRaK4UYIV",
        "colab_type": "text"
      },
      "source": [
        "Consider that you are in the current situation:\n",
        "\n",
        "``\n",
        "I have two columns in my data file with 5,000 rows, column 1 is time (with 1 hour interval) and column 2 is the number of sales and I am trying to forecast the number of sales for future time steps. Help me to set the number of samples, time steps and features in this data for an LSTM?\n",
        "``\n",
        "\n",
        "There are few problems here:\n",
        "\n",
        "* **Data Shape**: LSTMs expect 3D input, and it can be challenging to get your head around this the first time.\n",
        "* **Sequence Length**: LSTMs don't like sequences of more than 200-400 time steps, so the data will need to be split into subsamples.\n",
        "\n",
        "We will work through this example, broken down into the following 4 steps:\n",
        "\n",
        "1. Load the Data\n",
        "2. Drop the Time Column\n",
        "3. Split Into Samples\n",
        "4. Reshape Subsequences\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-gyJQj3q9pi_",
        "colab_type": "text"
      },
      "source": [
        "### Load the Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZmkMCCYbTyXt",
        "colab_type": "code",
        "outputId": "0440844a-5526-4d48-c426-e746f62dc2ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "# load time series dataset\n",
        "# series = pd.read_csv('filename.csv', header=0, index_col=0)\n",
        "\n",
        "# We will mock loading by defining a new dataset in memory with 5,000 time steps.\n",
        "# define the dataset\n",
        "data = list()\n",
        "n = 5000\n",
        "for i in range(n):\n",
        "  data.append([i+1, (i+1) * 10])\n",
        "data = np.array(data)\n",
        "print(data[:5, :])\n",
        "print(data.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 1 10]\n",
            " [ 2 20]\n",
            " [ 3 30]\n",
            " [ 4 40]\n",
            " [ 5 50]]\n",
            "(5000, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zw-RUV2f_Yd2",
        "colab_type": "text"
      },
      "source": [
        "We can see we have 5,000 rows and 2 columns: a standard univariate time series dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "542e2v6C_dG2",
        "colab_type": "text"
      },
      "source": [
        "### Drop the Time Column"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WAjSbvB1_eJF",
        "colab_type": "text"
      },
      "source": [
        "If your time series data is uniform over time and there is no missing values, we can drop the time column. If not, you may want to look at imputing the missing values, resampling the data to a new time scale, or developing a model that can handle missing values. \n",
        "\n",
        "Here, we just drop the first column:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8mjJx7WA-616",
        "colab_type": "code",
        "outputId": "4640c8eb-b26b-4d73-cdd4-d85b72484e74",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# define the dataset\n",
        "data = list()\n",
        "n = 5000\n",
        "for i in range(n):\n",
        "  data.append([i+1, (i+1) * 10])\n",
        "data = np.array(data)\n",
        "\n",
        "# drop time\n",
        "data = data[:, 1]\n",
        "print(data.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "87O-C78ZAmCe",
        "colab_type": "text"
      },
      "source": [
        "### Split Into Samples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zgUU1CGtAmz7",
        "colab_type": "text"
      },
      "source": [
        "LSTMs need to process samples where each sample is a single sequence of observations. In this case, 5,000 time steps is too long; LSTMs work better with 200-to-400 time steps. Therefore, we need to split the 5,000 time steps into multiple shorter sub-sequences.\n",
        "\n",
        "For example, perhaps you need overlapping sequences, perhaps non-overlapping is good but your model needs state across the sub-sequences and so on. \n",
        "\n",
        "In this example, we will split the 5,000 time steps into 25 sub-sequences of 200 time steps each."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8I7z_g2GAOOL",
        "colab_type": "code",
        "outputId": "8d85658e-fdbb-462c-fdf5-a92c99bd276f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# define the dataset\n",
        "data = list()\n",
        "n = 5000\n",
        "for i in range(n):\n",
        "  data.append([i+1, (i+1) * 10])\n",
        "data = np.array(data)\n",
        "\n",
        "# drop time\n",
        "data = data[:, 1]\n",
        "print(data.shape)\n",
        "\n",
        "# split into samples (e.g. 5000/200 = 25)\n",
        "samples = list()\n",
        "length = 200\n",
        "\n",
        "# step over the 5,000 in jumps of 200\n",
        "for i in range(0, n , length):\n",
        "  sample = data[i: i + length]  # grab from i to i + 200\n",
        "  samples.append(sample)\n",
        "print(len(samples))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5000,)\n",
            "25\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_a-AsEPVBtoz",
        "colab_type": "code",
        "outputId": "d93e2a85-fbfc-4cc1-cd1f-70668e3f8207",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(samples[:5][0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "200"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mLGjwEFHB46O",
        "colab_type": "code",
        "outputId": "72536606-1d3e-417e-a3b7-8992eb08f1f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 663
        }
      },
      "source": [
        "samples[:2]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([  10,   20,   30,   40,   50,   60,   70,   80,   90,  100,  110,\n",
              "         120,  130,  140,  150,  160,  170,  180,  190,  200,  210,  220,\n",
              "         230,  240,  250,  260,  270,  280,  290,  300,  310,  320,  330,\n",
              "         340,  350,  360,  370,  380,  390,  400,  410,  420,  430,  440,\n",
              "         450,  460,  470,  480,  490,  500,  510,  520,  530,  540,  550,\n",
              "         560,  570,  580,  590,  600,  610,  620,  630,  640,  650,  660,\n",
              "         670,  680,  690,  700,  710,  720,  730,  740,  750,  760,  770,\n",
              "         780,  790,  800,  810,  820,  830,  840,  850,  860,  870,  880,\n",
              "         890,  900,  910,  920,  930,  940,  950,  960,  970,  980,  990,\n",
              "        1000, 1010, 1020, 1030, 1040, 1050, 1060, 1070, 1080, 1090, 1100,\n",
              "        1110, 1120, 1130, 1140, 1150, 1160, 1170, 1180, 1190, 1200, 1210,\n",
              "        1220, 1230, 1240, 1250, 1260, 1270, 1280, 1290, 1300, 1310, 1320,\n",
              "        1330, 1340, 1350, 1360, 1370, 1380, 1390, 1400, 1410, 1420, 1430,\n",
              "        1440, 1450, 1460, 1470, 1480, 1490, 1500, 1510, 1520, 1530, 1540,\n",
              "        1550, 1560, 1570, 1580, 1590, 1600, 1610, 1620, 1630, 1640, 1650,\n",
              "        1660, 1670, 1680, 1690, 1700, 1710, 1720, 1730, 1740, 1750, 1760,\n",
              "        1770, 1780, 1790, 1800, 1810, 1820, 1830, 1840, 1850, 1860, 1870,\n",
              "        1880, 1890, 1900, 1910, 1920, 1930, 1940, 1950, 1960, 1970, 1980,\n",
              "        1990, 2000]),\n",
              " array([2010, 2020, 2030, 2040, 2050, 2060, 2070, 2080, 2090, 2100, 2110,\n",
              "        2120, 2130, 2140, 2150, 2160, 2170, 2180, 2190, 2200, 2210, 2220,\n",
              "        2230, 2240, 2250, 2260, 2270, 2280, 2290, 2300, 2310, 2320, 2330,\n",
              "        2340, 2350, 2360, 2370, 2380, 2390, 2400, 2410, 2420, 2430, 2440,\n",
              "        2450, 2460, 2470, 2480, 2490, 2500, 2510, 2520, 2530, 2540, 2550,\n",
              "        2560, 2570, 2580, 2590, 2600, 2610, 2620, 2630, 2640, 2650, 2660,\n",
              "        2670, 2680, 2690, 2700, 2710, 2720, 2730, 2740, 2750, 2760, 2770,\n",
              "        2780, 2790, 2800, 2810, 2820, 2830, 2840, 2850, 2860, 2870, 2880,\n",
              "        2890, 2900, 2910, 2920, 2930, 2940, 2950, 2960, 2970, 2980, 2990,\n",
              "        3000, 3010, 3020, 3030, 3040, 3050, 3060, 3070, 3080, 3090, 3100,\n",
              "        3110, 3120, 3130, 3140, 3150, 3160, 3170, 3180, 3190, 3200, 3210,\n",
              "        3220, 3230, 3240, 3250, 3260, 3270, 3280, 3290, 3300, 3310, 3320,\n",
              "        3330, 3340, 3350, 3360, 3370, 3380, 3390, 3400, 3410, 3420, 3430,\n",
              "        3440, 3450, 3460, 3470, 3480, 3490, 3500, 3510, 3520, 3530, 3540,\n",
              "        3550, 3560, 3570, 3580, 3590, 3600, 3610, 3620, 3630, 3640, 3650,\n",
              "        3660, 3670, 3680, 3690, 3700, 3710, 3720, 3730, 3740, 3750, 3760,\n",
              "        3770, 3780, 3790, 3800, 3810, 3820, 3830, 3840, 3850, 3860, 3870,\n",
              "        3880, 3890, 3900, 3910, 3920, 3930, 3940, 3950, 3960, 3970, 3980,\n",
              "        3990, 4000])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IbVK-Ys3CYwX",
        "colab_type": "text"
      },
      "source": [
        "We now have 25 subsequences of 200 time steps each."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xz_5OcmkCZgA",
        "colab_type": "text"
      },
      "source": [
        "### Reshape Subsequences"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0uUaycRYCb2p",
        "colab_type": "text"
      },
      "source": [
        "The LSTM needs data with the format of $[samples, timesteps, features]$. We have 25 samples, 200 time steps per sample, and 1 feature. \n",
        "\n",
        "First, we need to convert our list of arrays into a 2D NumPy array with the shape $[25, 200]$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q3ajkmluCJRv",
        "colab_type": "code",
        "outputId": "7212540b-3c40-47b1-9cd1-4ac6880739a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# define the dataset\n",
        "data = list()\n",
        "n = 5000\n",
        "for i in range(n):\n",
        "  data.append([i+1, (i+1) * 10])\n",
        "data = np.array(data)\n",
        "\n",
        "# drop time\n",
        "data = data[:, 1]\n",
        "print(data.shape)\n",
        "\n",
        "# split into samples (e.g. 5000/200 = 25)\n",
        "samples = list()\n",
        "length = 200\n",
        "\n",
        "# step over the 5,000 in jumps of 200\n",
        "for i in range(0, n , length):\n",
        "  sample = data[i: i + length]  # grab from i to i + 200\n",
        "  samples.append(sample)\n",
        "print(len(samples))\n",
        "\n",
        "# convert list of arrays into 2d array\n",
        "data = np.array(samples)\n",
        "print(data.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5000,)\n",
            "25\n",
            "(25, 200)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D8h6xdRHDhSw",
        "colab_type": "text"
      },
      "source": [
        "Now we have 25 rows and 200 columns. Interpreted in a machine learning context, this dataset has 25 samples and 200 features per sample.\n",
        "\n",
        "Next, we can use the reshape() function to add one additional dimension for our single feature and use the existing columns as time steps instead."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XtVdYk5GDVxS",
        "colab_type": "code",
        "outputId": "fdb05035-4ec3-436d-d5e8-1d152967aea4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# reshape into [samples, timesteps, features]\n",
        "data = data.reshape((len(samples), length, 1))\n",
        "print(data.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(25, 200, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PLR6f3RUEMTj",
        "colab_type": "text"
      },
      "source": [
        "And that is it. The data can now be used as an input (X) to an LSTM model, or even a CNN model."
      ]
    }
  ]
}